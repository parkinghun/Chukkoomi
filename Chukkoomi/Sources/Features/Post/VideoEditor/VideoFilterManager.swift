//
//  VideoFilterManager.swift
//  Chukkoomi
//
//  Created by ê¹€ì˜í›ˆ on 11/15/25.
//

import UIKit
import AVFoundation
@preconcurrency import CoreImage
import Vision
import CoreML
import Metal

/// ë¹„ë””ì˜¤ í•„í„° íƒ€ì…
enum VideoFilter: String, CaseIterable, Equatable {
    case blackAndWhite = "í‘ë°±"
    case warm = "ë”°ëœ»í•œ"
    case cool = "ì°¨ê°‘ê²Œ"
    case animeGANHayao = "ê·¸ë¦¼"
    
    var displayName: String {
        return rawValue
    }
}

/// ë¹„ë””ì˜¤ í•„í„° ê´€ë¦¬ì
struct VideoFilterManager {
    
    /// ë¹„ë””ì˜¤ì— í•„í„°ë¥¼ ì ìš©í•œ AVVideoComposition ìƒì„±
    /// - Parameters:
    ///   - asset: ì›ë³¸ ë¹„ë””ì˜¤ AVAsset
    ///   - filter: ì ìš©í•  í•„í„°
    ///   - targetSize: ëª©í‘œ í¬ê¸° (nilì´ë©´ ì›ë³¸ í¬ê¸° ì‚¬ìš©)
    /// - Returns: í•„í„°ê°€ ì ìš©ëœ AVVideoComposition (í•„í„°ê°€ ì—†ìœ¼ë©´ nil)
    static func createVideoComposition(
        for asset: AVAsset,
        filter: VideoFilter?,
        targetSize: CGSize? = nil,
        isPortraitFromPHAsset: Bool
    ) async -> AVVideoComposition? {
        // í•„í„°ê°€ ì—†ìœ¼ë©´ nil ë°˜í™˜
        guard let filter = filter else {
            return nil
        }
        
        // ë¹„ë””ì˜¤ íŠ¸ë™ ê°€ì ¸ì˜¤ê¸°
        guard let videoTrack = try? await asset.loadTracks(withMediaType: .video).first else {
            return nil
        }
        
        let naturalSize = try? await videoTrack.load(.naturalSize)
        let preferredTransform = try? await videoTrack.load(.preferredTransform)
        
        guard let naturalSize = naturalSize else {
            return nil
        }
        
        // ë””ë²„ê¹… ë¡œê·¸
        print("ğŸ¬ [VideoFilterManager] ====== í•„í„° ì ìš© ì‹œì‘ ======")
        print("ğŸ¬ [VideoFilterManager] ì›ë³¸ naturalSize: \(naturalSize)")
        print("ğŸ¬ [VideoFilterManager] isPortraitFromPHAsset: \(isPortraitFromPHAsset)")
        print("ğŸ¬ [VideoFilterManager] targetSize íŒŒë¼ë¯¸í„°: \(targetSize ?? .zero)")
        
        // naturalSizeê°€ ê°€ë¡œ ë°©í–¥ì¸ì§€ í™•ì¸
        let isNaturalSizePortrait = naturalSize.width < naturalSize.height
        print("ğŸ¬ [VideoFilterManager] isNaturalSizePortrait: \(isNaturalSizePortrait)")
        
        // ì„¸ë¡œ ì˜ìƒì¸ë° naturalSizeê°€ ê°€ë¡œë¡œ ë‚˜ì˜¨ ê²½ìš° swap
        let adjustedNaturalSize: CGSize
        if isPortraitFromPHAsset && !isNaturalSizePortrait {
            adjustedNaturalSize = CGSize(width: naturalSize.height, height: naturalSize.width)
            print("ğŸ¬ [VideoFilterManager] naturalSize swap: \(adjustedNaturalSize)")
        } else {
            adjustedNaturalSize = naturalSize
            print("ğŸ¬ [VideoFilterManager] naturalSize ìœ ì§€: \(adjustedNaturalSize)")
        }
        
        // renderSize ê³„ì‚°
        let renderSize = targetSize ?? adjustedNaturalSize
        print("ğŸ¬ [VideoFilterManager] renderSize: \(renderSize)")

        // renderSize ë°©í–¥ í™•ì¸
        let isRenderSizePortrait = renderSize.width < renderSize.height
        print("ğŸ¬ [VideoFilterManager] isRenderSizePortrait: \(isRenderSizePortrait)")

        // renderSizeì™€ naturalSizeì˜ ë°©í–¥ì´ ë‹¤ë¥´ë©´ 90ë„ íšŒì „ í•„ìš”
        let needsRotation = isRenderSizePortrait != isNaturalSizePortrait
        let correctedTransform: CGAffineTransform
        if needsRotation {
            correctedTransform = CGAffineTransform(a: 0, b: 1, c: -1, d: 0, tx: 0, ty: 0)
            print("ğŸ¬ [VideoFilterManager] âœ… 90ë„ íšŒì „ transform ì ìš© (renderSizeì™€ naturalSize ë°©í–¥ ë¶ˆì¼ì¹˜)")
        } else {
            correctedTransform = preferredTransform ?? .identity
            print("ğŸ¬ [VideoFilterManager] ì›ë³¸ transform ì‚¬ìš© (ë°©í–¥ ì¼ì¹˜)")
        }
        print("ğŸ¬ [VideoFilterManager] ====== í•„í„° ì ìš© ì¢…ë£Œ ======")


        // aspect-fit ìŠ¤ì¼€ì¼ ê³„ì‚° (íšŒì „ ì „ naturalSize ê¸°ì¤€)
        let scaleX = renderSize.width / (needsRotation ? naturalSize.height : naturalSize.width)
        let scaleY = renderSize.height / (needsRotation ? naturalSize.width : naturalSize.height)
        let scale = min(scaleX, scaleY)
        print("ğŸ¬ [VideoFilterManager] scale: \(scale) (scaleX: \(scaleX), scaleY: \(scaleY))")
        
        // ì¤‘ì•™ ì •ë ¬ì„ ìœ„í•œ offset ê³„ì‚° (ì›ë³¸ naturalSize ê¸°ì¤€)
        let scaledWidth = naturalSize.width * scale
        let scaledHeight = naturalSize.height * scale
        print("ğŸ¬ [VideoFilterManager] scaledWidth: \(scaledWidth), scaledHeight: \(scaledHeight)")

        let offsetX: CGFloat
        let offsetY: CGFloat

        if needsRotation {
            // íšŒì „í•˜ëŠ” ê²½ìš°: 90ë„ íšŒì „ í›„ ì¤‘ì•™ ì •ë ¬
            offsetX = (renderSize.width - scaledHeight) / 2
            offsetY = (renderSize.height - scaledWidth) / 2
        } else {
            // íšŒì „ ë¶ˆí•„ìš”: ì¼ë°˜ ì¤‘ì•™ ì •ë ¬
            offsetX = (renderSize.width - scaledWidth) / 2
            offsetY = (renderSize.height - scaledHeight) / 2
        }
        print("ğŸ¬ [VideoFilterManager] offset: (\(offsetX), \(offsetY))")
        
        // AVVideoComposition ìƒì„± (í•„í„° + ë¦¬ì‚¬ì´ì¦ˆë¥¼ CIImageë¡œ ì²˜ë¦¬)
        let composition = AVMutableVideoComposition(
            asset: asset,
            applyingCIFiltersWithHandler: { request in
                var outputImage = request.sourceImage

                print("ğŸ¨ [VideoFilterManager CIFilter] ====== í”„ë ˆì„ ì²˜ë¦¬ ì‹œì‘ ======")
                print("ğŸ¨ [VideoFilterManager CIFilter] ì›ë³¸ extent: \(outputImage.extent)")
                print("ğŸ¨ [VideoFilterManager CIFilter] renderSize: \(renderSize)")

                // ì‹¤ì œ extent ê¸°ì¤€ìœ¼ë¡œ ë°©í–¥ í™•ì¸ (CIImageëŠ” ì´ë¯¸ íšŒì „ëœ extentë¥¼ ê°€ì§)
                let sourceExtent = outputImage.extent
                let isSourcePortrait = sourceExtent.width < sourceExtent.height
                let isRenderPortrait = renderSize.width < renderSize.height
                let actualNeedsRotation = isSourcePortrait != isRenderPortrait

                print("ğŸ¨ [VideoFilterManager CIFilter] isSourcePortrait: \(isSourcePortrait)")
                print("ğŸ¨ [VideoFilterManager CIFilter] isRenderPortrait: \(isRenderPortrait)")
                print("ğŸ¨ [VideoFilterManager CIFilter] actualNeedsRotation: \(actualNeedsRotation)")

                // 1. í•„í„° ì ìš©
                outputImage = applyFilter(filter, to: outputImage, originalImage: outputImage, targetSize: nil)

                // 2. ë¦¬ì‚¬ì´ì§• ë° íšŒì „ (extent ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨)
                let actualScale: CGFloat
                let actualTransform: CGAffineTransform

                if actualNeedsRotation {
                    // íšŒì „ í•„ìš”: extent ê¸°ì¤€ìœ¼ë¡œ scale ê³„ì‚°
                    let scaleX = renderSize.width / sourceExtent.height
                    let scaleY = renderSize.height / sourceExtent.width
                    actualScale = min(scaleX, scaleY)
                    actualTransform = CGAffineTransform(a: 0, b: 1, c: -1, d: 0, tx: 0, ty: 0)
                    print("ğŸ¨ [VideoFilterManager CIFilter] íšŒì „ O - scale: \(actualScale)")
                } else {
                    // íšŒì „ ë¶ˆí•„ìš”
                    let scaleX = renderSize.width / sourceExtent.width
                    let scaleY = renderSize.height / sourceExtent.height
                    actualScale = min(scaleX, scaleY)
                    actualTransform = .identity
                    print("ğŸ¨ [VideoFilterManager CIFilter] íšŒì „ X - scale: \(actualScale)")
                }

                let scaleTransform = CGAffineTransform(scaleX: actualScale, y: actualScale)
                let transformWithRotation = scaleTransform.concatenating(actualTransform)

                outputImage = outputImage.transformed(by: transformWithRotation)

                // 3. transform í›„ extent ì •ê·œí™” (ìŒìˆ˜ ì¢Œí‘œë¥¼ ì›ì ìœ¼ë¡œ)
                let transformedExtent = outputImage.extent
                print("ğŸ¨ [VideoFilterManager CIFilter] transformedExtent: \(transformedExtent)")

                if transformedExtent.origin.x != 0 || transformedExtent.origin.y != 0 {
                    let normalizeTransform = CGAffineTransform(
                        translationX: -transformedExtent.origin.x,
                        y: -transformedExtent.origin.y
                    )
                    outputImage = outputImage.transformed(by: normalizeTransform)
                    print("ğŸ¨ [VideoFilterManager CIFilter] normalized extent: \(outputImage.extent)")
                }

                // 4. ì¤‘ì•™ ì •ë ¬ì„ ìœ„í•œ offset ê³„ì‚° (extent ê¸°ì¤€)
                let currentExtent = outputImage.extent
                let scaledWidth = sourceExtent.width * actualScale
                let scaledHeight = sourceExtent.height * actualScale

                let actualOffsetX: CGFloat
                let actualOffsetY: CGFloat

                if actualNeedsRotation {
                    // íšŒì „í•˜ëŠ” ê²½ìš°: 90ë„ íšŒì „ í›„ ì¤‘ì•™ ì •ë ¬
                    actualOffsetX = (renderSize.width - scaledHeight) / 2
                    actualOffsetY = (renderSize.height - scaledWidth) / 2
                } else {
                    // íšŒì „ ë¶ˆí•„ìš”: ì¼ë°˜ ì¤‘ì•™ ì •ë ¬
                    actualOffsetX = (renderSize.width - scaledWidth) / 2
                    actualOffsetY = (renderSize.height - scaledHeight) / 2
                }

                print("ğŸ¨ [VideoFilterManager CIFilter] actualOffsetX: \(actualOffsetX), actualOffsetY: \(actualOffsetY)")

                let translateTransform = CGAffineTransform(translationX: actualOffsetX, y: actualOffsetY)
                outputImage = outputImage.transformed(by: translateTransform)
                print("ğŸ¨ [VideoFilterManager CIFilter] after translate extent: \(outputImage.extent)")

                // 5. ê²€ì • ë°°ê²½ ìƒì„± (ë¹ˆ ê³µê°„ì„ ì±„ìš°ê¸° ìœ„í•´)
                let background = CIImage(color: CIColor.black).cropped(to: CGRect(origin: .zero, size: renderSize))

                // 6. ì´ë¯¸ì§€ë¥¼ ë°°ê²½ ìœ„ì— í•©ì„± (outputImageì˜ extent originì— ë”°ë¼ ìœ„ì¹˜ ê²°ì •)
                let composited = outputImage.composited(over: background)
                print("ğŸ¨ [VideoFilterManager CIFilter] composited extent: \(composited.extent)")

                // 7. renderSize ì˜ì—­ìœ¼ë¡œ crop
                let finalOutput = composited.cropped(to: CGRect(origin: .zero, size: renderSize))
                print("ğŸ¨ [VideoFilterManager CIFilter] final extent: \(finalOutput.extent)")
                print("ğŸ¨ [VideoFilterManager CIFilter] ====== í”„ë ˆì„ ì²˜ë¦¬ ì™„ë£Œ ======")
                
                // GPU ê°€ì† ì»¨í…ìŠ¤íŠ¸ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
                request.finish(with: finalOutput, context: VideoFilterHelper.gpuContext)
            }
        )
        
        composition.renderSize = renderSize
        
        return composition
    }
    
    // MARK: - Private Helper Methods
    
    /// CIImageì— í•„í„° ì ìš© (VideoFilterHelper ì‚¬ìš©)
    private static func applyFilter(_ filter: VideoFilter, to image: CIImage, originalImage: CIImage, targetSize: CGSize? = nil) -> CIImage {
        return VideoFilterHelper.applyFilter(filter, to: image, originalImage: originalImage, targetSize: targetSize)
    }
    
    /// ë¹„ë””ì˜¤ orientation í™•ì¸ í—¬í¼
    private static func orientation(from transform: CGAffineTransform) -> (orientation: UIImage.Orientation, isPortrait: Bool) {
        var assetOrientation = UIImage.Orientation.up
        var isPortrait = false
        
        if transform.a == 0 && transform.b == 1.0 && transform.c == -1.0 && transform.d == 0 {
            assetOrientation = .right
            isPortrait = true
        } else if transform.a == 0 && transform.b == -1.0 && transform.c == 1.0 && transform.d == 0 {
            assetOrientation = .left
            isPortrait = true
        } else if transform.a == 1.0 && transform.b == 0 && transform.c == 0 && transform.d == 1.0 {
            assetOrientation = .up
        } else if transform.a == -1.0 && transform.b == 0 && transform.c == 0 && transform.d == -1.0 {
            assetOrientation = .down
        }
        
        return (assetOrientation, isPortrait)
    }
}
