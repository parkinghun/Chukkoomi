//
//  VideoCompositorWithSubtitles.swift
//  Chukkoomi
//
//  Created by ê¹€ì˜í›ˆ on 11/20/25.
//

import AVFoundation
@preconcurrency import CoreImage
import UIKit
import Metal

/// í•„í„°ì™€ ìë§‰ ì •ë³´ë¥¼ ë‹´ì€ ì»¤ìŠ¤í…€ Instruction
final class SubtitleVideoCompositionInstruction: NSObject, AVVideoCompositionInstructionProtocol {
    var timeRange: CMTimeRange
    var enablePostProcessing: Bool = false
    var containsTweening: Bool = false
    var requiredSourceTrackIDs: [NSValue]?
    var passthroughTrackID: CMPersistentTrackID = kCMPersistentTrackID_Invalid
    
    let filter: VideoFilter?
    let subtitles: [EditVideoFeature.Subtitle]
    let trimStartTime: Double
    let layerInstructions: [AVVideoCompositionLayerInstruction]
    
    // ë¦¬ì‚¬ì´ì§• ì •ë³´
    let naturalSize: CGSize
    let renderSize: CGSize
    let scale: CGFloat
    let offsetX: CGFloat
    let offsetY: CGFloat
    let correctedTransform: CGAffineTransform
    let isPortraitFromPHAsset: Bool
    
    init(
        timeRange: CMTimeRange,
        filter: VideoFilter?,
        subtitles: [EditVideoFeature.Subtitle],
        trimStartTime: Double,
        sourceTrackIDs: [NSValue],
        layerInstructions: [AVVideoCompositionLayerInstruction],
        naturalSize: CGSize,
        renderSize: CGSize,
        scale: CGFloat,
        offsetX: CGFloat,
        offsetY: CGFloat,
        correctedTransform: CGAffineTransform,
        isPortraitFromPHAsset: Bool
    ) {
        self.timeRange = timeRange
        self.filter = filter
        self.subtitles = subtitles
        self.trimStartTime = trimStartTime
        self.requiredSourceTrackIDs = sourceTrackIDs
        self.layerInstructions = layerInstructions
        self.naturalSize = naturalSize
        self.renderSize = renderSize
        self.scale = scale
        self.offsetX = offsetX
        self.offsetY = offsetY
        self.correctedTransform = correctedTransform
        self.isPortraitFromPHAsset = isPortraitFromPHAsset
        super.init()
    }
}

/// í•„í„°ì™€ ìë§‰ì„ í”„ë ˆì„ë³„ë¡œ ì²˜ë¦¬í•˜ëŠ” ì»¤ìŠ¤í…€ Video Compositor
final class VideoCompositorWithSubtitles: NSObject, AVVideoCompositing {
    
    // MARK: - Properties
    
    private let renderContext: CIContext
    private let renderQueue = DispatchQueue(label: "com.chukkoomi.videocompositor", qos: .userInitiated)
    
    // MARK: - AVVideoCompositing Required Properties
    
    nonisolated var sourcePixelBufferAttributes: [String : any Sendable]? {
        return [
            kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA,
            kCVPixelBufferMetalCompatibilityKey as String: true
        ]
        
    }
    
    nonisolated var requiredPixelBufferAttributesForRenderContext: [String : any Sendable] {
        return [
            kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA,
            kCVPixelBufferMetalCompatibilityKey as String: true
        ]
    }
    
    // MARK: - Initialization
    
    required override init() {
        // GPU ê°€ì†ì„ ìœ„í•œ Metal ê¸°ë°˜ CIContext ìƒì„±
        if let metalDevice = MTLCreateSystemDefaultDevice() {
            self.renderContext = CIContext(mtlDevice: metalDevice, options: [
                .useSoftwareRenderer: false,
                .priorityRequestLow: false
            ])
        } else {
            self.renderContext = CIContext(options: [.useSoftwareRenderer: false])
        }
        
        super.init()
    }
    
    // MARK: - AVVideoCompositing Methods
    
    func renderContextChanged(_ newRenderContext: AVVideoCompositionRenderContext) {
        // ë Œë” ì»¨í…ìŠ¤íŠ¸ ë³€ê²½ ì‹œ ì²˜ë¦¬ (í•„ìš”ì‹œ)
    }
    
    func startRequest(_ asyncVideoCompositionRequest: AVAsynchronousVideoCompositionRequest) {
        renderQueue.async { [weak self] in
            guard let self = self else {
                asyncVideoCompositionRequest.finish(with: NSError(
                    domain: "VideoCompositor",
                    code: -1,
                    userInfo: [NSLocalizedDescriptionKey: "Compositor deallocated"]
                ))
                return
            }
            
            // Custom instructionì—ì„œ í•„í„°ì™€ ìë§‰ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            guard let instruction = asyncVideoCompositionRequest.videoCompositionInstruction as? SubtitleVideoCompositionInstruction else {
                asyncVideoCompositionRequest.finish(with: NSError(
                    domain: "VideoCompositor",
                    code: -1,
                    userInfo: [NSLocalizedDescriptionKey: "Invalid instruction type"]
                ))
                return
            }
            
            // ì†ŒìŠ¤ í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°
            guard let sourcePixelBuffer = asyncVideoCompositionRequest.sourceFrame(byTrackID: asyncVideoCompositionRequest.sourceTrackIDs[0].int32Value) else {
                asyncVideoCompositionRequest.finish(with: NSError(
                    domain: "VideoCompositor",
                    code: -1,
                    userInfo: [NSLocalizedDescriptionKey: "Failed to get source frame"]
                ))
                return
            }
            
            // CIImageë¡œ ë³€í™˜
            var outputImage = CIImage(cvPixelBuffer: sourcePixelBuffer)

            print("ğŸï¸ [VideoCompositor] ====== í”„ë ˆì„ ì²˜ë¦¬ ì‹œì‘ ======")
            print("ğŸï¸ [VideoCompositor] ì›ë³¸ extent: \(outputImage.extent)")
            print("ğŸï¸ [VideoCompositor] instruction.renderSize: \(instruction.renderSize)")
            print("ğŸï¸ [VideoCompositor] instruction.correctedTransform: \(instruction.correctedTransform)")

            // 1. í•„í„° ì ìš©
            if let filter = instruction.filter {
                outputImage = self.applyFilter(filter, to: outputImage)
            }

            // 2. ì›ë³¸ ë¹„ë””ì˜¤ì˜ preferredTransformì„ ë¨¼ì € ì ìš© (raw í”½ì…€ì„ ì‹¤ì œ ë°©í–¥ìœ¼ë¡œ)
            if instruction.correctedTransform != .identity {
                print("ğŸï¸ [VideoCompositor] ì›ë³¸ preferredTransform ì ìš© ì „ extent: \(outputImage.extent)")
                outputImage = outputImage.transformed(by: instruction.correctedTransform)
                print("ğŸï¸ [VideoCompositor] ì›ë³¸ preferredTransform ì ìš© í›„ extent: \(outputImage.extent)")

                // transform í›„ extent ì •ê·œí™”
                if outputImage.extent.origin.x != 0 || outputImage.extent.origin.y != 0 {
                    let normalizeTransform = CGAffineTransform(
                        translationX: -outputImage.extent.origin.x,
                        y: -outputImage.extent.origin.y
                    )
                    outputImage = outputImage.transformed(by: normalizeTransform)
                    print("ğŸï¸ [VideoCompositor] preferredTransform í›„ normalized extent: \(outputImage.extent)")
                }
            }

            // 3. ì‹¤ì œ extent ê¸°ì¤€ìœ¼ë¡œ ë°©í–¥ í™•ì¸
            let sourceExtent = outputImage.extent
            let isSourcePortrait = sourceExtent.width < sourceExtent.height
            let isRenderPortrait = instruction.renderSize.width < instruction.renderSize.height
            let actualNeedsRotation = isSourcePortrait != isRenderPortrait

            print("ğŸï¸ [VideoCompositor] ì‹¤ì œ sourceExtent (transform í›„): \(sourceExtent)")
            print("ğŸï¸ [VideoCompositor] isSourcePortrait: \(isSourcePortrait)")
            print("ğŸï¸ [VideoCompositor] isRenderPortrait: \(isRenderPortrait)")
            print("ğŸï¸ [VideoCompositor] actualNeedsRotation: \(actualNeedsRotation)")

            // 3. ë¦¬ì‚¬ì´ì§• ë° íšŒì „ (extent ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨)
            let actualScale: CGFloat
            let actualTransform: CGAffineTransform

            if actualNeedsRotation {
                // íšŒì „ í•„ìš”: extent ê¸°ì¤€ìœ¼ë¡œ scale ê³„ì‚°
                let scaleX = instruction.renderSize.width / sourceExtent.height
                let scaleY = instruction.renderSize.height / sourceExtent.width
                actualScale = min(scaleX, scaleY)
                actualTransform = CGAffineTransform(a: 0, b: 1, c: -1, d: 0, tx: 0, ty: 0)
                print("ğŸï¸ [VideoCompositor] íšŒì „ O - scale: \(actualScale)")
            } else {
                // íšŒì „ ë¶ˆí•„ìš”
                let scaleX = instruction.renderSize.width / sourceExtent.width
                let scaleY = instruction.renderSize.height / sourceExtent.height
                actualScale = min(scaleX, scaleY)
                actualTransform = .identity
                print("ğŸï¸ [VideoCompositor] íšŒì „ X - scale: \(actualScale)")
            }

            let scaleTransform = CGAffineTransform(scaleX: actualScale, y: actualScale)
            print("ğŸï¸ [VideoCompositor] scaleTransform: \(scaleTransform)")
            print("ğŸï¸ [VideoCompositor] actualTransform (íšŒì „): \(actualTransform)")

            let transformWithRotation = scaleTransform.concatenating(actualTransform)
            print("ğŸï¸ [VideoCompositor] ìµœì¢… transform (scale + rotation): \(transformWithRotation)")
            print("ğŸï¸ [VideoCompositor] transform ì ìš© ì „ extent: \(outputImage.extent)")

            outputImage = outputImage.transformed(by: transformWithRotation)
            print("ğŸï¸ [VideoCompositor] transform ì ìš© í›„ extent: \(outputImage.extent)")

            // 4. transform í›„ extent ì •ê·œí™” (ìŒìˆ˜ ì¢Œí‘œë¥¼ ì›ì ìœ¼ë¡œ)
            let transformedExtent = outputImage.extent
            print("ğŸï¸ [VideoCompositor] transformedExtent: \(transformedExtent)")

            if transformedExtent.origin.x != 0 || transformedExtent.origin.y != 0 {
                let normalizeTransform = CGAffineTransform(
                    translationX: -transformedExtent.origin.x,
                    y: -transformedExtent.origin.y
                )
                outputImage = outputImage.transformed(by: normalizeTransform)
                print("ğŸï¸ [VideoCompositor] normalized extent: \(outputImage.extent)")
            }

            // 5. ì¤‘ì•™ ì •ë ¬ì„ ìœ„í•œ offset ê³„ì‚° (extent ê¸°ì¤€)
            let scaledWidth = sourceExtent.width * actualScale
            let scaledHeight = sourceExtent.height * actualScale

            let actualOffsetX: CGFloat
            let actualOffsetY: CGFloat

            if actualNeedsRotation {
                // íšŒì „í•˜ëŠ” ê²½ìš°: 90ë„ íšŒì „ í›„ ì¤‘ì•™ ì •ë ¬
                actualOffsetX = (instruction.renderSize.width - scaledHeight) / 2
                actualOffsetY = (instruction.renderSize.height - scaledWidth) / 2
            } else {
                // íšŒì „ ë¶ˆí•„ìš”: ì¼ë°˜ ì¤‘ì•™ ì •ë ¬
                actualOffsetX = (instruction.renderSize.width - scaledWidth) / 2
                actualOffsetY = (instruction.renderSize.height - scaledHeight) / 2
            }

            print("ğŸï¸ [VideoCompositor] actualOffsetX: \(actualOffsetX), actualOffsetY: \(actualOffsetY)")

            let translateTransform = CGAffineTransform(translationX: actualOffsetX, y: actualOffsetY)
            outputImage = outputImage.transformed(by: translateTransform)
            print("ğŸï¸ [VideoCompositor] after translate extent: \(outputImage.extent)")

            // 5. ê²€ì • ë°°ê²½ ìƒì„± (ë¹ˆ ê³µê°„ì„ ì±„ìš°ê¸° ìœ„í•´)
            let background = CIImage(color: CIColor.black).cropped(to: CGRect(origin: .zero, size: instruction.renderSize))

            // 6. ì´ë¯¸ì§€ë¥¼ ë°°ê²½ ìœ„ì— í•©ì„± (outputImageì˜ extent originì— ë”°ë¼ ìœ„ì¹˜ ê²°ì •)
            outputImage = outputImage.composited(over: background)
            print("ğŸï¸ [VideoCompositor] composited extent: \(outputImage.extent)")

            // 7. renderSize ì˜ì—­ìœ¼ë¡œ crop
            outputImage = outputImage.cropped(to: CGRect(origin: .zero, size: instruction.renderSize))
            print("ğŸï¸ [VideoCompositor] cropped extent: \(outputImage.extent)")

            // 8. ìë§‰ ì ìš©
            let currentTime = CMTimeGetSeconds(asyncVideoCompositionRequest.compositionTime)
            let adjustedTime = currentTime + instruction.trimStartTime

            if let subtitle = self.findSubtitle(at: adjustedTime, subtitles: instruction.subtitles) {
                if let subtitleImage = self.createSubtitleImage(
                    text: subtitle.text,
                    videoSize: instruction.renderSize
                ) {
                    // ìë§‰ ì´ë¯¸ì§€ë¥¼ ë¹„ë””ì˜¤ í”„ë ˆì„ ìœ„ì— í•©ì„±
                    outputImage = subtitleImage.composited(over: outputImage)
                    print("ğŸï¸ [VideoCompositor] ìë§‰ í•©ì„± í›„ extent: \(outputImage.extent)")
                }
            }

            print("ğŸï¸ [VideoCompositor] ìµœì¢… extent: \(outputImage.extent)")
            print("ğŸï¸ [VideoCompositor] ====== í”„ë ˆì„ ì²˜ë¦¬ ì™„ë£Œ ======")

            // 9. ë Œë”ë§ (Core Image Y-up â†’ ë¹„ë””ì˜¤ ë²„í¼ Y-down ë³´ì •)
            guard let renderPixelBuffer = asyncVideoCompositionRequest.renderContext.newPixelBuffer() else {
                asyncVideoCompositionRequest.finish(with: NSError(
                    domain: "VideoCompositor",
                    code: -1,
                    userInfo: [NSLocalizedDescriptionKey: "Failed to create render pixel buffer"]
                ))
                return
            }

            self.renderContext.render(outputImage, to: renderPixelBuffer)
            asyncVideoCompositionRequest.finish(withComposedVideoFrame: renderPixelBuffer)
        }
    }
    
    func cancelAllPendingVideoCompositionRequests() {
        // ëª¨ë“  ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ ì·¨ì†Œ
    }
    
    // MARK: - Private Helper Methods
    
    /// í•„í„° ì ìš© (VideoFilterHelper ì‚¬ìš©)
    private func applyFilter(_ filter: VideoFilter, to image: CIImage) -> CIImage {
        // AnimeGANì€ ë„ˆë¬´ ë¬´ê±°ì›Œì„œ ì‹¤ì‹œê°„ ì²˜ë¦¬ ë¶ˆê°€ - ì»¤ìŠ¤í…€ compositorì—ì„œëŠ” ìŠ¤í‚µ
        if filter == .animeGANHayao {
            return image
        }
        return VideoFilterHelper.applyFilter(filter, to: image)
    }
    
    /// í˜„ì¬ ì‹œê°„ì— í•´ë‹¹í•˜ëŠ” ìë§‰ ì°¾ê¸°
    private func findSubtitle(at time: Double, subtitles: [EditVideoFeature.Subtitle]) -> EditVideoFeature.Subtitle? {
        return subtitles.first { subtitle in
            time >= subtitle.startTime && time < subtitle.endTime
        }
    }
    
    /// ìë§‰ ì´ë¯¸ì§€ ìƒì„± (ë¯¸ë¦¬ë³´ê¸°ì™€ ë™ì¼í•œ ìŠ¤íƒ€ì¼)
    private func createSubtitleImage(text: String, videoSize: CGSize) -> CIImage? {
        // ë§¤ìš° ë†’ì€ í•´ìƒë„ë¡œ ë Œë”ë§í•˜ì—¬ ë¦¬ì‚¬ì´ì§• í›„ì—ë„ ì„ ëª…ë„ ìœ ì§€
        let renderScale: CGFloat = 4.0
        
        // ìë§‰ í¬ê¸°ë¥¼ ê³ ì • (iPhone Max ì„¸ë¡œ ê¸°ì¤€: 1320px)
        let baseWidth: CGFloat = 1320.0
        let baseFontSize: CGFloat = baseWidth * 0.06  // ì•½ 79pt
        let fontSize = baseFontSize * renderScale
        
        let font = UIFont.boldSystemFont(ofSize: fontSize)
        
        let paragraphStyle = NSMutableParagraphStyle()
        paragraphStyle.alignment = .center
        
        // í°ìƒ‰ í…ìŠ¤íŠ¸ ì†ì„±
        let whiteAttributes: [NSAttributedString.Key: Any] = [
            .font: font,
            .foregroundColor: UIColor.white,
            .paragraphStyle: paragraphStyle
        ]
        
        // ê²€ì • í…Œë‘ë¦¬ ì†ì„±
        let blackAttributes: [NSAttributedString.Key: Any] = [
            .font: font,
            .foregroundColor: UIColor.black,
            .paragraphStyle: paragraphStyle
        ]
        
        let whiteString = NSAttributedString(string: text, attributes: whiteAttributes)
        let blackString = NSAttributedString(string: text, attributes: blackAttributes)
        
        // í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
        let maxWidth = baseWidth * renderScale * 0.9
        let textSize = whiteString.boundingRect(
            with: CGSize(width: maxWidth, height: .greatestFiniteMagnitude),
            options: [.usesLineFragmentOrigin, .usesFontLeading],
            context: nil
        ).size
        
        // ì—¬ë°± ì¶”ê°€ (í…Œë‘ë¦¬ offsetì„ ê³ ë ¤í•˜ì—¬ ë” í¬ê²Œ)
        let outlineOffset: CGFloat = 2.0 * renderScale
        let padding: CGFloat = 20.0 * renderScale + outlineOffset
        let imageSize = CGSize(
            width: textSize.width + padding * 2,
            height: textSize.height + padding * 2
        )
        
        // UIGraphicsImageRendererë¡œ ê³ í•´ìƒë„ í…ìŠ¤íŠ¸ ë Œë”ë§
        let format = UIGraphicsImageRendererFormat()
        format.scale = 1.0
        format.opaque = false
        
        let renderer = UIGraphicsImageRenderer(size: imageSize, format: format)
        let image = renderer.image { context in
            UIColor.clear.setFill()
            context.fill(CGRect(origin: .zero, size: imageSize))
            
            let textRect = CGRect(
                x: padding,
                y: padding,
                width: textSize.width,
                height: textSize.height
            )
            
            // ë¯¸ë¦¬ë³´ê¸°ì™€ ë™ì¼í•˜ê²Œ 8ë°©í–¥ ê²€ì • í…Œë‘ë¦¬ ê·¸ë¦¬ê¸°
            for i in 0..<8 {
                let offsetX = CGFloat(i % 3 - 1) * outlineOffset
                let offsetY = CGFloat(i / 3 - 1) * outlineOffset
                
                let outlineRect = textRect.offsetBy(dx: offsetX, dy: offsetY)
                blackString.draw(in: outlineRect)
            }
            
            // í°ìƒ‰ í…ìŠ¤íŠ¸ (ì¤‘ì•™)
            whiteString.draw(in: textRect)
        }
        
        // UIImageë¥¼ CIImageë¡œ ë³€í™˜
        guard let cgImage = image.cgImage else {
            return nil
        }
        
        var textImage = CIImage(cgImage: cgImage)
        
        // ê¸°ì¤€ í¬ê¸°ë¡œ ìŠ¤ì¼€ì¼ ë‹¤ìš´ (renderScale ë°°ìˆ˜ë§Œí¼)
        let scaleDown = CGAffineTransform(scaleX: 1.0 / renderScale, y: 1.0 / renderScale)
        textImage = textImage.transformed(by: scaleDown)
        
        // ì‹¤ì œ ë¹„ë””ì˜¤ í¬ê¸°ì— ë§ê²Œ ìë§‰ í¬ê¸° ì¡°ì •
        let videoScale = videoSize.width / baseWidth
        let finalScale = CGAffineTransform(scaleX: videoScale, y: videoScale)
        textImage = textImage.transformed(by: finalScale)
        
        // í…ìŠ¤íŠ¸ë¥¼ ë¹„ë””ì˜¤ ì¤‘ì•™ í•˜ë‹¨ì— ë°°ì¹˜
        // Core ImageëŠ” ì¢Œí•˜ë‹¨ì´ (0,0)
        let textExtent = textImage.extent
        let xPosition = (videoSize.width - textExtent.width) / 2
        let yPosition = videoSize.height * 0.05 // í•˜ë‹¨ì—ì„œ 5% ìœ„ì¹˜ (ë” ì•„ë˜ë¡œ)
        
        textImage = textImage.transformed(by: CGAffineTransform(
            translationX: xPosition,
            y: yPosition
        ))
        
        return textImage
    }
}

